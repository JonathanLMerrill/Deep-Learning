{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxxyfVlxVWqv"
   },
   "source": [
    "<a \n",
    "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab6.ipynb\"\n",
    "  target=\"_parent\">\n",
    "  <img\n",
    "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
    "    alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cksgAH12XRjV"
   },
   "source": [
    "# Sequence-to-sequence models\n",
    "\n",
    "### Description:\n",
    "For this lab, you will code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
    "\n",
    "This lab will help you develop several new skills, as well as understand some best practices needed for building large models. In addition, we'll be able to create networks that generate neat text!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7bdZWxvJrsx",
    "outputId": "77c96b7e-b651-44d1-c8f0-a10161853561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-19 04:00:45--  https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz\n",
      "Resolving piazza.com (piazza.com)... 52.205.194.150, 18.235.185.127, 18.215.222.38, ...\n",
      "Connecting to piazza.com (piazza.com)|52.205.194.150|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz [following]\n",
      "--2023-02-19 04:00:45--  https://cdn-uploads.piazza.com/attach/jlifkda6h0x5bk/hzosotq4zil49m/jn13x09arfeb/text_files.tar.gz\n",
      "Resolving cdn-uploads.piazza.com (cdn-uploads.piazza.com)... 52.84.18.123, 52.84.18.115, 52.84.18.16, ...\n",
      "Connecting to cdn-uploads.piazza.com (cdn-uploads.piazza.com)|52.84.18.123|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1533290 (1.5M) [application/x-gzip]\n",
      "Saving to: ‘./text_files.tar.gz’\n",
      "\n",
      "./text_files.tar.gz 100%[===================>]   1.46M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2023-02-19 04:00:45 (22.2 MB/s) - ‘./text_files.tar.gz’ saved [1533290/1533290]\n",
      "\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.8/dist-packages (1.3.6)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
      "file_len = 51572\n"
     ]
    }
   ],
   "source": [
    "! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
    "! tar -xzf text_files.tar.gz\n",
    "! pip install unidecode\n",
    "! pip install torch\n",
    "\n",
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    " \n",
    "import pdb\n",
    "import gc\n",
    " \n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "file = unidecode.unidecode(open('./Empire_Strikes_Back.txt').read())\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxBeKeNjJ0NQ",
    "outputId": "7bbce474-fcde-4e40-ba61-8f41eace1491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: Your Highness, we must take this last transport. It's our  only hope.\n",
      "LEIA: (to controller) Send all troops in sector twelve to the south  slope to protect the fighters.\n",
      "ANNOUNCER: (over loudspeaker\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    " \n",
    "def random_chunk():\n",
    "  start_index = random.randint(0, file_len - chunk_len)\n",
    "  end_index = start_index + chunk_len + 1\n",
    "  return file[start_index:end_index]\n",
    "  \n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "On0_WitWJ99e",
    "outputId": "0dad7d9a-9608-4893-cd64-7d8ded83a453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 11, 12, 39, 40, 41])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "  tensor = torch.zeros(len(string)).long()\n",
    "  for c in range(len(string)):\n",
    "      tensor[c] = all_characters.index(string[c])\n",
    "  return tensor\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYJPTLcaYmfI"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 4: Creating your own GRU cell \n",
    "\n",
    "**(Come back to this later - its defined here so that the GRU will be defined before it is used)**\n",
    "\n",
    "---\n",
    "\n",
    "The cell that you used in Part 1 was a pre-defined Pytorch layer. Now, write your own GRU class using the same parameters as the built-in Pytorch class does.\n",
    "\n",
    "Please try not to look at the GRU cell definition. The answer is right there in the code, and in theory, you could just cut-and-paste it. This bit is on your honor!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aavAv50ZKQ-F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GRU(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_layers):\n",
    "    super(GRU, self).__init__()\n",
    "    self.__dict__.update(locals())\n",
    "\n",
    "    # Define weight matrices for update gate, reset gate, and new memory cell\n",
    "    self.update_gate_input_weights = nn.Linear(input_size, hidden_size)\n",
    "    self.update_gate_hidden_weights = nn.Linear(hidden_size, hidden_size)\n",
    "    self.reset_gate_input_weights = nn.Linear(input_size, hidden_size)\n",
    "    self.reset_gate_hidden_weights = nn.Linear(hidden_size, hidden_size)\n",
    "    self.new_memory_cell_input_weights = nn.Linear(input_size, hidden_size)\n",
    "    self.new_memory_cell_hidden_weights = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "  def forward(self, inputs, hidden):\n",
    "    current_input = inputs\n",
    "    updated_hidden_state = torch.clone(hidden)\n",
    "\n",
    "    # Iterate over each layer and compute the output and hidden state\n",
    "    for layer_index in range(self.num_layers):\n",
    "      current_hidden_state = hidden[layer_index].unsqueeze(0)\n",
    "\n",
    "      # Compute update gate, reset gate, and new memory cell\n",
    "      update_gate = torch.sigmoid(\n",
    "          self.update_gate_input_weights(current_input) + \n",
    "          self.update_gate_hidden_weights(current_hidden_state)\n",
    "      )\n",
    "      reset_gate = torch.sigmoid(\n",
    "          self.reset_gate_input_weights(current_input) +\n",
    "          self.reset_gate_hidden_weights(current_hidden_state)\n",
    "      )\n",
    "      new_memory_cell = torch.tanh(\n",
    "          self.new_memory_cell_input_weights(current_input) +\n",
    "          reset_gate * self.new_memory_cell_hidden_weights(current_hidden_state)\n",
    "      )\n",
    "\n",
    "      # Compute the output of this layer as a weighted combination of old and new memory cells\n",
    "      layer_output = (1 - update_gate) * new_memory_cell + update_gate * current_hidden_state\n",
    "\n",
    "      current_input = torch.clone(layer_output)\n",
    "      updated_hidden_state[layer_index] = torch.clone(layer_output.squeeze(0))\n",
    "\n",
    "    return current_input, updated_hidden_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qtXdX-B_WiAY"
   },
   "source": [
    "---\n",
    "\n",
    "##  Part 1: Building a sequence to sequence model\n",
    "\n",
    "---\n",
    "\n",
    "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
    "\n",
    "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "d6tNdEnzWj5F"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):\n",
    "    super(RNN, self).__init__()\n",
    "    self.input_dim = input_dim\n",
    "    self.hidden_dim = hidden_dim\n",
    "    self.output_dim = output_dim\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    # initialize layers\n",
    "    self.out_layer = nn.Linear(hidden_dim, output_dim)\n",
    "    self.softmax_layer = nn.LogSoftmax(dim=1)\n",
    "    self.embedding_layer = nn.Embedding(input_dim, hidden_dim)\n",
    "    self.gru_layer = nn.GRU(hidden_dim, hidden_dim, num_layers=num_layers)\n",
    "\n",
    "  def forward(self, input_token, hidden_state):\n",
    "    # embed the input token\n",
    "    embedded = self.embedding_layer(input_token).view(1, 1, -1)\n",
    "    \n",
    "    # pass through the GRU layer\n",
    "    output, hidden_state = self.gru_layer(embedded, hidden_state)\n",
    "    \n",
    "    # pass through the output layer\n",
    "    output = self.softmax_layer(self.out_layer(output[0]))\n",
    "    \n",
    "    return output, hidden_state\n",
    "\n",
    "  def init_hidden(self):\n",
    "    # initialize the hidden state with zeros\n",
    "    return torch.zeros(self.num_layers, 1, self.hidden_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hrhXghEPKD-5"
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "  chunk = random_chunk()\n",
    "  inp = char_tensor(chunk[:-1])\n",
    "  target = char_tensor(chunk[1:])\n",
    "  return inp, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZpiGObbBX0Mr"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 2: Sample text and Training information\n",
    "\n",
    "---\n",
    "\n",
    "We now want to be able to train our network, and sample text after training.\n",
    "\n",
    "This function outlines how training a sequence style network goes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "2ALC3Pf8Kbsi"
   },
   "outputs": [],
   "source": [
    "# NOTE: decoder_optimizer, decoder, and criterion will be defined below as global variables\n",
    "def train(input_sequence, target_sequence):\n",
    "  \"\"\"\n",
    "  Train the decoder model on a given input and target sequence.\n",
    "\n",
    "  Args:\n",
    "  - input_sequence: tensor of shape (seq_len, batch_size) representing the input sequence\n",
    "  - target_sequence: tensor of shape (seq_len, batch_size) representing the target sequence\n",
    "\n",
    "  Returns:\n",
    "  - loss: average loss over the input sequence\n",
    "  \"\"\"\n",
    "\n",
    "  # Move data to GPU\n",
    "  input_sequence = input_sequence.cuda()\n",
    "  target_sequence = target_sequence.cuda()\n",
    "\n",
    "  # Initialize hidden state, set up gradient and loss\n",
    "  decoder_optimizer.zero_grad()\n",
    "  hidden_state = decoder.init_hidden()\n",
    "  hidden_state = hidden_state.cuda()\n",
    "  loss = 0\n",
    "\n",
    "  # Loop over the input sequence and pass through decoder\n",
    "  for i in range(len(input_sequence)):\n",
    "    output, hidden_state = decoder(input_sequence[i], hidden_state)\n",
    "    loss += criterion(output, target_sequence[i].unsqueeze(0).long())\n",
    "\n",
    "  # Compute average loss over the input sequence\n",
    "  avg_loss = loss / len(input_sequence)\n",
    "\n",
    "  # Backpropagate and update weights\n",
    "  avg_loss.backward()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  # Collect garbage to free up memory\n",
    "  gc.collect()\n",
    "\n",
    "  return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EN06NUu3YRlz"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 3: Sample text and Training information\n",
    "\n",
    "---\n",
    "\n",
    "You can at this time, if you choose, also write out your train loop boilerplate that samples random sequences and trains your RNN. This will be helpful to have working before writing your own GRU class.\n",
    "\n",
    "If you are finished training, or during training, and you want to sample from the network you may consider using the following function. If your RNN model is instantiated as `decoder`then this will probabilistically sample a sequence of length `predict_len`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "B-bp-OZ1KjNh"
   },
   "outputs": [],
   "source": [
    "def sample_outputs(output_tensor, temperature):\n",
    "    \"\"\"Takes in a tensor of unnormalized probability weights and samples a character from the distribution\"\"\"\n",
    "    # As temperature approaches 0, this sampling function becomes argmax (no randomness)\n",
    "    # As temperature approaches infinity, this sampling function becomes a purely random choice\n",
    "    return torch.multinomial(torch.exp(output_tensor / temperature), 1)\n",
    "\n",
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    # Initialize the hidden state\n",
    "    hidden_state = decoder.init_hidden()\n",
    "    hidden_state = hidden_state.cuda()\n",
    "    \n",
    "    # Convert the prime string to a tensor\n",
    "    prime_tensor = char_tensor(prime_str)\n",
    "\n",
    "    # Create an empty output string\n",
    "    output_str = \"\"\n",
    "\n",
    "    # Use the RNN to generate a sequence of characters\n",
    "    for c in prime_tensor:\n",
    "        c = c.cuda()\n",
    "        output_tensor, hidden_state = decoder(c, hidden_state)\n",
    "        output_str += all_characters[c]\n",
    "\n",
    "    # Sample the next character using the output tensor and temperature\n",
    "    char = sample_outputs(output_tensor, temperature)\n",
    "    output_str += all_characters[char]\n",
    "\n",
    "    for _ in range(predict_len):\n",
    "        # Use the RNN to generate the next character based on the previous one\n",
    "        output_tensor, hidden_state = decoder(char, hidden_state)\n",
    "        char = sample_outputs(output_tensor, temperature)\n",
    "        output_str += all_characters[char]\n",
    "\n",
    "        gc.collect()\n",
    "    \n",
    "    return output_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du4AGA8PcFEW"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 4: (Create a GRU cell, requirements above)\n",
    "\n",
    "---\n",
    "See Above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFS2bpHSZEU6"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Part 5: Run it and generate some text!\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-nXFeCmdKodw"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "n_epochs = 5000\n",
    "print_every = 200\n",
    "plot_every = 10\n",
    "hidden_size = 200\n",
    "n_layers = 3\n",
    "lr = 0.001\n",
    " \n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder.cuda()\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    " \n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star Wars Episode 4 trained on 5000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8g7Ydb6ngNPQ",
    "outputId": "65312f87-c3ba-421d-c2e4-eb52c1c50e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55.644516706466675 (200 4%) 2.4834]\n",
      "Whice the the thicg on?  I'm thurre the the you rote or you'lg prike it reeqsson you won wip'l the tere \n",
      "\n",
      "[110.88877010345459 (400 8%) 2.0227]\n",
      "What.\n",
      "BEN\tWas wibke mang with pime womd to wepion.  Foron of wo me moll, feed the hearder.\n",
      "LKE\tWhive, t \n",
      "\n",
      "[166.90313148498535 (600 12%) 1.5227]\n",
      "Wheatliding hereted your of of for got Luke about in you're that wich chanter?. we're the scamed this n \n",
      "\n",
      "[221.76067900657654 (800 16%) 1.3210]\n",
      "What we luce easpatooning to is power.  Ellobince this tyou're\n",
      "LUKE\tThat's my on to be is to me the sho \n",
      "\n",
      "[277.2848732471466 (1000 20%) 1.8521]\n",
      "What suget what son you.  The planet sight, Sefted the say too kir.  Luke, the but they're goodn.?.\n",
      "OAN \n",
      "\n",
      "[332.47766184806824 (1200 24%) 1.4516]\n",
      "What?  He-was we am Peeary that wait.  At a the entater anengaage.\n",
      "THREEPIO\tWhat be a remut comuont!\n",
      "WI \n",
      "\n",
      "[387.5787003040314 (1400 28%) 1.3492]\n",
      "Whide him!\n",
      "BIGGS\tLuke, we'll see thing ideary and belong has light.  Dowbating to restraining there of  \n",
      "\n",
      "[442.9913229942322 (1600 32%) 1.6327]\n",
      "WhaJned so!\n",
      "LEIA\tThe Imperial.  You've got have no this all fwells magneted in that back to recuase out \n",
      "\n",
      "[498.2022514343262 (1800 36%) 1.0038]\n",
      "Whould me and my faler.\n",
      "VADER\tYou sentret it.\n",
      "LUKE\tThey're not to the Alderaan.\n",
      "THREEPIO\tWhat's he don' \n",
      "\n",
      "[553.619401216507 (2000 40%) 1.1306]\n",
      "What would be now.\n",
      "LUKE\tBut what?\n",
      "THRAEPIO\tSir, I have it!\n",
      "GANTR INTERCOOPER\tWe don't know come to thin \n",
      "\n",
      "[608.7166833877563 (2200 44%) 1.2253]\n",
      "WhAN\tI don't need reSaporators to the main controled for your father.Yet much a weapon.  Qupsty in rang \n",
      "\n",
      "[664.5830109119415 (2400 48%) 1.2770]\n",
      "When in the blast how wortrol.\n",
      "HAN\tWhere go for all.\n",
      "THREEPIO\tThey're going to small the learn haven't  \n",
      "\n",
      "[719.7586965560913 (2600 52%) 0.9190]\n",
      "What's what you going to get imagination.  I have gonna negative!  I think we're going to you as going  \n",
      "\n",
      "[775.5776014328003 (2800 56%) 1.4069]\n",
      "What into something sight.  And have the Force, but you can't have been of the shut.  It did it?\n",
      "BIGGS\t \n",
      "\n",
      "[831.3368363380432 (3000 60%) 0.9563]\n",
      "Wht you think we are approaching, sir.\n",
      "LUKE\tYou know, I pupil of the Rebel Jase.  Fear me...\n",
      "HAN\tI don' \n",
      "\n",
      "[886.7369918823242 (3200 64%) 0.9676]\n",
      "What way.  I suggest a chain me, sir, but them!  Owen, I'll pay you are going to me?  It's a prime, sir \n",
      "\n",
      "[942.2724583148956 (3400 68%) 0.9838]\n",
      "Where.  Take you are?\n",
      "LUKE\tHow did you are directly thing.  Noh, hell a will be able to her.  There's w \n",
      "\n",
      "[997.3082091808319 (3600 72%) 0.7773]\n",
      "Who's R2 unit we are speed me the exhaust person.  The ship back has far our loast down the far minutes \n",
      "\n",
      "[1052.968302488327 (3800 76%) 0.9201]\n",
      "Where, so kind of the Rebellion?  It's a lot of their chance, but there's something level of my experie \n",
      "\n",
      "[1108.2019271850586 (4000 80%) 1.0133]\n",
      "When we can disand one-five, but I'm afraid me...  I've had to Alderaan.\n",
      "VADER\tThere's a lot of fact, I \n",
      "\n",
      "[1164.2034394741058 (4200 84%) 0.9455]\n",
      "What old maneuvers.\n",
      "THREEPIO\tWait, Your Highness, plus a probleming out, Artoo.  It's the graid of his  \n",
      "\n",
      "[1220.3814022541046 (4400 88%) 0.7385]\n",
      "What old master.\n",
      "THREEPIO\tSir, wouldr up they have a big hurry.  How witian before you sure this battle \n",
      "\n",
      "[1276.156381368637 (4600 92%) 0.7253]\n",
      "Whis only soon be able to Sand Greedo.\n",
      "BEN\tDon't close all your rear to destroy a moore in there number \n",
      "\n",
      "[1332.839844942093 (4800 96%) 0.8001]\n",
      "Whis outh fight to be able to much right, yeard in his pilot us.\n",
      "LUKE\tWatch your station, if missed by  \n",
      "\n",
      "[2593.8582763671875 (5000 100%) 0.8178]\n",
      "Who's time!\n",
      "THREEPIO\tHe's got on the Force, Luke.\n",
      "LUKE\tOh, this is just signing for the Ambassador.  Yo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  loss_ = train(*random_training_set())       \n",
    "  loss_avg += loss_\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
    "      print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "  if epoch % plot_every == 0:\n",
    "      all_losses.append(loss_avg / plot_every)\n",
    "      loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star Wars Episode 4 trained on 2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKfozqw-6eqb",
    "outputId": "0adecf45-cb4d-4b0c-d9d7-0c2117fa3619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.8585844039917 (200 10%) 2.2002]\n",
      "Whe time you on.\n",
      "HA\tThet ctels to to an us ope.  poout fo of e?  I thile sits mere in.\n",
      "DEEDAJE\tI're tal \n",
      "\n",
      "[114.11068654060364 (400 20%) 1.8987]\n",
      "Where a sir?\n",
      "LUKE\tThas an ely the dame on to baster to look to cing no this mader shay.\n",
      "LUKE\tHan you a  \n",
      "\n",
      "[171.93142342567444 (600 30%) 1.4160]\n",
      "What ontle bade deacharder of something of bad thened soon to fand never for wruntione...\n",
      "THREEPIO\tRed  \n",
      "\n",
      "[230.01735305786133 (800 40%) 1.7505]\n",
      "Whed jest destrol will see.\n",
      "OHBEN\tThere the Artoo prich the dererfored of and their that the beal you c \n",
      "\n",
      "[287.9912483692169 (1000 50%) 1.5858]\n",
      "Where in...  I want and the could be the simp o on.\n",
      "RED BERU\tCome it.  It's they get.  I'll father an t \n",
      "\n",
      "[344.7105243206024 (1200 60%) 1.5703]\n",
      "Whan sir.\n",
      "BPER\tGet he was away.  He scut any in out of they ring in.\n",
      "BEN\tWe've got me could have below  \n",
      "\n",
      "[401.58359265327454 (1400 70%) 1.1625]\n",
      "Where.\n",
      "HAN\tI'm course him.\n",
      "THREEPIO\tA mind, bego been here!  I'm going to your eeters.  I can gale ship \n",
      "\n",
      "[458.7983522415161 (1600 80%) 1.2586]\n",
      "What a little droids.  We've got to Fon any a lottation to fly might it.  Look, he's going to be down t \n",
      "\n",
      "[515.6406986713409 (1800 90%) 1.3140]\n",
      "Where starturning to well with that not side to their ship resproctors.\n",
      "RED LEADER\t...\n",
      "LUKE\tThen one we \n",
      "\n",
      "[572.5773322582245 (2000 100%) 1.1262]\n",
      "When don't we the boold terminate the station to what's fast use the should big to they're got to have  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  loss_ = train(*random_training_set())       \n",
    "  loss_avg += loss_\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
    "      print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "  if epoch % plot_every == 0:\n",
    "      all_losses.append(loss_avg / plot_every)\n",
    "      loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I just ran the code you gave us, but I realized that's probably specific for LOTR so I ran it with star wars specific values later. This is Star Wars IV trained on 5000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ee0so6aKJ5L8",
    "outputId": "1112f361-6a7a-4756-dbb2-2a66494172fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ra\n",
      " range.\n",
      "OWEN\tThey're those approaching in the Sand People all right.\n",
      "LUKE\tWhat's that you real going to reward can fordow, it's the Rebel stiming us in the computer on the directors.  It must leamy far li \n",
      "\n",
      " Th\n",
      " Threepio!\n",
      "BEN\tThe had be with me.  I think she this operal some bither than informations.\n",
      "LUKE\tWhat are the glacse.\n",
      "LUKE\tIt listen the be the have beamed so seconding into be seem plans the found the det \n",
      "\n",
      " ra\n",
      " rafter a big before the Rebel base!\n",
      "BEN\tI think those brother will be the Xedine.  See you know, the shooting into run this bear quibling.\n",
      "RED LEADER\tHan, Luke, the Rebel base by is things.\n",
      "BEN\tI don't h \n",
      "\n",
      " G\n",
      " Get have to things this close timuse.  I said.\n",
      "LUKE\tBut there cull all because the main range.\n",
      "GIRST TROVOICE\tBlast is my back this haven't regafte them!\n",
      "RED TEN\tArtoo, it's nothing... at the Rebel base \n",
      "\n",
      " ra\n",
      " rack me, can't make it and like them?\n",
      "LUKE\tWhat a big it!\n",
      "THREEPIO\tYou report the Rebel shick in some back one.\n",
      "THREEPIO\tWhat is councels!  This standing in... he right are done.?.. where are plans.  I w \n",
      "\n",
      " ca\n",
      " came to be Rebel Luke!\n",
      "BEN\tDon't looks okay it could Alderaan spoice.\n",
      "BEN\tNot agreew is it.\n",
      "AUNT We've a stirty in counternor-bid you new just lock minus make my little help, they magne mamped there's no \n",
      "\n",
      " he\n",
      " her, she did by clasted.\n",
      "BEN\tWe're to the end card out of never handing that filing on through able the take the before\n",
      "RED TEN\tThose will try boy?.. what I'll be all right?\n",
      "BANT I SECAN\trange?\n",
      "HAN\tMange \n",
      "\n",
      " I \n",
      " I have creactor one the Rebel base estar Ward my and important this ship!\n",
      "LEIA\tBut they is.\n",
      "HAN\tWhere is is cournal throop the Rebel sition the battle so or the sounds you life coming through you said us \n",
      "\n",
      " I \n",
      " I know what lot this one?\n",
      "TARKIN\tWake open?\n",
      "LUKE\tWhat inwante!  We'll be this side friendss where comingine.\n",
      "BEN\tWe'll make that your found him risking you going to be side the Rebel Scansabight?\n",
      "TROOPER \n",
      "\n",
      " ra\n",
      " rather sir... and not the Rebel Luitime... and if he be transport me coming through his mind, sir.\n",
      "HAN\tNot like I have the Rebel base.\n",
      "LUKE\tBoy, it's like that little from her?  I feel this Obin-Wan dest \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
    "  start = random.randint(0,len(start_strings)-1)\n",
    "  print(start_strings[start])\n",
    "#   all_characters.index(string[c])\n",
    "  print(evaluate(start_strings[start], 200), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Star Wars IV trained on 2000 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "firRgQDQtkud",
    "outputId": "476dfb6a-7e90-4b28-86d8-efb4ecc584e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lo\n",
      " lot of this.  So you'll be right three five?\n",
      "GREEDO\tIf you've got to at going to be come for spies.  Some like do sometimes, and any threat.\n",
      "HAN\tYou're as far system.  You'd better have madness with you. \n",
      "\n",
      " lo\n",
      " long time by to be on the side of a canyon was your sad directly carries.\n",
      "GREEDO\tThey're my right above his for you, kid.  I've known here for anything computer.\n",
      "HAN\tYou needn't collody.\n",
      "FIRST TROOPER\tDo \n",
      "\n",
      " lo\n",
      " locked in a choice?\n",
      "GREEDO\tThey're mady neflic minutes, but they're going to be any mouth before of the Rebellion is crusape a time.  I think you should do who has do able to hide them!  See those one mo \n",
      "\n",
      " ca\n",
      " came back to you, business.\n",
      "LUKE\tIt's too you.  He did his place can be first-spead us than a big hurry.  He needs you.  You're podrate them from with the down side of this ship about them!  Look, and no \n",
      "\n",
      " ca\n",
      " cay only hope.\n",
      "HAN\tWhat a can be approas one now.\n",
      "LUKE\tYou can do before a compart the detention severs.\n",
      "HAN\tWhat they're made the commander.  The scanner Biggs and not gotta hold to hide to play back fo \n",
      "\n",
      " Th\n",
      " Threepio!  Sign out of here ships, where is a battle station.  Keep you think of here?\n",
      "LUKE\tThreepio!\n",
      "HAN\tYeah, I think you think hold to see your stories and a choice!\n",
      "GREEDS\tLock who thought you've bee \n",
      "\n",
      " Th\n",
      " Threepio!  She'll be to stop our side of the help, Luke.\n",
      "HAN\tWhater!\n",
      "LUKE\tThey're just side and in life our boss.  You may far an enough to the sections at the plans through him.\n",
      "LUKE\tLook at the right s \n",
      "\n",
      " ca\n",
      " can be to see so bold with me!\n",
      "THREEPIO\tHe's got out there!\n",
      "THREEPIO\tIt's too be before you, Luke!\n",
      "LEIA\tLuke, take you are?\n",
      "THREEPIO\tYou go go your handiworking ssfors.  We do you get it contically accil \n",
      "\n",
      " wh\n",
      " who drop this ship now.  She's here to pupil owner of some minutes.\n",
      "BEN\tYou know, I just can be ready dark side of your ships!  Look, I can't hold them myself!  Well, most considerain, any other way out  \n",
      "\n",
      " Th\n",
      " Threepio!  Cover to be on my capading for the Force.\n",
      "LEIA\tThey're as you aready.\n",
      "LEIA\tAt loobing a droid, and hold them!\n",
      "RED LEADER\tAre you going?\n",
      "HAN\tYeah, but I'd make them.\n",
      "HAN\tYeah, but I'd make me b \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
    "  start = random.randint(0,len(start_strings)-1)\n",
    "  print(start_strings[start])\n",
    "#   all_characters.index(string[c])\n",
    "  print(evaluate(start_strings[start], 200), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJhgDc2IauPE"
   },
   "source": [
    "---\n",
    "\n",
    "## Part 6: Generate output on a different dataset\n",
    "\n",
    "---\n",
    "I sort of did this above but this I ran it all again on Star Wars 5 Data\n",
    "\n",
    "2000 Epochs Specific to star wars stars:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPegBAOxuF5u",
    "outputId": "2d2ad4ff-ec9c-40a4-a9a2-fd1766740da7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEN\n",
      "BEN\tOll a lot of for asking... and closing this station.\n",
      "TAGGE\tGo one day of your sorry, sir.  It looks like you as fancery will sometimes, but they're going to be carrying myself!\n",
      "TARKIN\tYou may be the F \n",
      "\n",
      " LEIA\n",
      " LEIA\tHe did you think a bad bad cnow the matter what you've been around.\n",
      "HAN\tYeah, but I'm survice is the survively troops.  Look, and in right for sure the blast me times Luke.  It's not much more going t \n",
      "\n",
      " LEIA\n",
      " LEIA\tLuke!\n",
      "LEIA\tHe's here!\n",
      "HAN\tBlast them!  See those one minute!\n",
      "CREVAN\tSecure them prody back home!\n",
      "BIGGS\tHurry up!  Fope!\n",
      "RED LEADER\tSwitch heartieve them!\n",
      "HAN\tIt could make this station qurpeder.  Look \n",
      "\n",
      "THREEPIO\n",
      "THREEPIO\tThe Owend on a drike, much this ship and do bolt here in him.  You're fortress to your Jady.\n",
      "LEIA\tHelp me, Obi-Wan Kenobi and I have to the Ambassador.  The Empire heard of the first sign of an extint \n",
      "\n",
      "LUKE\n",
      "LUKE\tAre you sure them?  They're our now complote of Anchorhead so pilot... them.\n",
      "HAN\tertoo!!  Cover with me!  You'll be a little rough on a secure this station is a little of a choice?\n",
      "GREEDO\tI've got to  \n",
      "\n",
      "LUKE\n",
      "LUKE\tYou'd better plans are not going to have been justisoned.\n",
      "LUKE\tWhere!\n",
      "LUKE\tHello, sir, come with me!\n",
      "THREEPIO\tWhat happened?\n",
      "LUKE\tThere is here!\n",
      "LUKE\tLook at they'd him?\n",
      "THREEPIO\tHelp!  Look!\n",
      "HAN\tYeah \n",
      "\n",
      " LEIA\n",
      " LEIA'S VOICE\tLuke, they're heavily a netweaghters going to have a dark speeder.  We don't you be a little rough bushpread down the jump on the survils afraid that side of Mos Eisley blasted systems will no \n",
      "\n",
      "LUKE\n",
      "LUKE\tThey're heading for come back!  Where is the blast set, you're going to have the cattle station of the Death Star point this one.\n",
      "LUKE\tWhere are you going?\n",
      "THREEPIO\tOh  I few stroped to rescue you!  B \n",
      "\n",
      " LEIA\n",
      " LEIA\tI've got to surpross faster Luke.\n",
      "THREEPIO\tIf you take it up this.\n",
      "THREEPIO\tHello, sir side us to blast your speeded and not going to have to help her.  You're pridess and ancient to sturbing.\n",
      "LUKE\tWh \n",
      "\n",
      "LUKE\n",
      "LUKE\tOkay, Artoo.\n",
      "THREEPIO\tHang on, Artoo.  An a straited do it!\n",
      "HAN\tWhat're you blast bay, what you're on a choice.\n",
      "LEIA\tAre the computer?\n",
      "LUKE\tWhat's you but these on, let's get out of course I found you \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  start_strings = [\"LUKE\", \"BEN\", \"THREEPIO\", \"HAN\", \" LEIA\", \"VADER\"]\n",
    "  start = random.randint(0,len(start_strings)-1)\n",
    "  print(start_strings[start])\n",
    "#   all_characters.index(string[c])\n",
    "  print(evaluate(start_strings[start], 200), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I wanted to get strings that had both Vader and Ben (Obi Wan) talking so I got 5 values where that true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jedKeMexu46G",
    "outputId": "4ffe16a2-bac2-437e-d628-ffe51c89118b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "BEN\tPrincess with your father me first.\n",
      "LUKE\tWhat was this detentions.\n",
      "VADER\tLuke, sir way out of your deflection of have don't controling on the plice all on tell the ike the be a princess.\n",
      "HAN\tI kides o\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "BEN\tYour up the got could on the fince... the droiddverse.  If that you do you coming your fast in the comtroc deflector sad the drime.  There are with entrol.\n",
      "VADER\tSeems coming our of the residing time.\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "BEN\tHidden with him.\n",
      "DODONNA\tWhat's meters!\n",
      "VADER\tI copy, I can do you didn't R2 uhe canture...\n",
      "VADER\tThe Force, where way droids.  You can't there's beapons!\n",
      "LEIA\tWe've got to disturbing?\n",
      "THREEPIO\tWhere \n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "VADER\tI have this things yourself faithing up the like the Force.\n",
      "T\n",
      "RED LEADER\tCan your ship came the seconds.  He don't want the plans of that of it.\n",
      "BEN\tWe're same first of the blast dest coming.\n",
      "RED TEN\t\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "BEN\tThe Force this droids.\n",
      "THREEPIO\tWe're sometimes.  I think?  They command Back thems.  I just religions good the jump to be this in the Death ThreeReped that a shape to there is this than ih...\n",
      "VADER\tI\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while count < 5:\n",
    "  start_strings = [\"LUKE\",\"BEN\",\"VADER\"]\n",
    "  start = random.randint(0,len(start_strings)-1)\n",
    "#   all_characters.index(string[c])\n",
    "  #print(evaluate(start_strings[start], 200), '\\n')\n",
    "  a = evaluate(start_strings[start], 200)\n",
    "  if a.find(\"BEN\") != -1 and a.find(\"VADER\") != -1:\n",
    "    print(count + 1)\n",
    "    print(a)\n",
    "    print(\"\\n\\n\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDFgTXBz0m7s"
   },
   "source": [
    "## Trained 2000 epochs on THE EMPIRE STRIKES BACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDqAPqUZ0p5_",
    "outputId": "ba440a19-e8af-4dfc-8986-a8dbf312f89f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1676779330.2258575 (200 10%) 1.4485]\n",
      "What's your powers will tell to the tractor them. \n",
      "YODA: Boy, lime on, yes. \n",
      "LANDO: Cimman. Becize. Bec \n",
      "\n",
      "[1676779390.4318273 (400 20%) 0.9943]\n",
      "What we seah. What is all right, it's all a coming out of pretty going to he train. very pesponder man. \n",
      "\n",
      "[1676779449.7285726 (600 30%) 1.0474]\n",
      "What! \n",
      "LEIA: What  can Wait and we're a garbage. Captain Solo? \n",
      "PIETT: All come it but him? \n",
      "HAN: (not  \n",
      "\n",
      "[1676779508.0417008 (800 40%) 0.9456]\n",
      "Why we can see there oped to get us.  quite ready had.  He could be a. \n",
      "HAN: (over srized  you preses e \n",
      "\n",
      "[1676779566.3804438 (1000 50%) 0.8931]\n",
      "What was  help you meen  all the Scoundrel, and we're  moves enough.\n",
      "LUKE: He will I have what I want t \n",
      "\n",
      "[1676779624.8161707 (1200 60%) 1.1207]\n",
      "Where and Reezed  hitthing getting carbance. \n",
      "HAN: (to Chewie) He? \n",
      "LEIA: Han, eare Imperial time.\n",
      "LEIA \n",
      "\n",
      "[1676779682.6477792 (1400 70%) 1.0179]\n",
      "What's getting the egal power to time to make sure the fleet. \n",
      "LANDO: You're a great as the fleet is no \n",
      "\n",
      "[1676779740.825743 (1600 80%) 1.0473]\n",
      "Wher's pregaan. I'm not so droid. \n",
      "LEIA: I don't even know who use you think your ships him. \n",
      "THREEPIO: \n",
      "\n",
      "[1676779799.3184655 (1800 90%) 0.6035]\n",
      "Where are set is to the  south entrance. \n",
      "LANDO: No station the directly is still will control it it th \n",
      "\n",
      "[1676779857.797504 (2000 100%) 1.0532]\n",
      "When the hyperdrive. \n",
      "LUKE: Ben...that was a subplart ships will leave. \n",
      "LEIA: You don't think you thou \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  loss_ = train(*random_training_set())       \n",
    "  loss_avg += loss_\n",
    "\n",
    "  if epoch % print_every == 0:\n",
    "      print('[%s (%d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_))\n",
    "      print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "  if epoch % plot_every == 0:\n",
    "      all_losses.append(loss_avg / plot_every)\n",
    "      loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversations between Yoda and Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D63iEupiu__0",
    "outputId": "e0c5649f-12da-40e1-aec3-2324ec4b5333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "YODA: (discouraged) A Jedi under the hyperdrive.\n",
      "VADER: Your standing coming ride. \n",
      "LUKE: Ben...I thought you pull hold.\n",
      "LEIA: Stop! \n",
      "LUKE: (into comlink) No, Chewie! \n",
      "LEIA: You must go. \n",
      "HAN: I'll got all\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "VADER: (over loudspeaker) I stupid there. \n",
      "pIETT: Why! \n",
      "YODA: Use there. \n",
      "HAN: Captain Solo...sir, why'll come his is long to get or tall. \n",
      "HAN: See you to speeder! You want more the parts and smell ships.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "YODA: You pulle. Only watch. \n",
      "ZEV: (into comlink) Yes, too. (laughs) Heavy around. \n",
      "YODA: Rold of the friends likely, you're almost a lot of me. Sometimes you must hope a mind. \n",
      "VADER: Release you get you \n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "YODA: (to save Ben... \n",
      "HAN: (into comlink) Hob you, that? \n",
      "VADER: (studying there's the hyperdrive. \n",
      "VADI Sound sure you all right. \n",
      "LEIA: So you're being trained so close.\n",
      "LANDO: But you garbage of the Th\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "VADER: It could be done ground sett the hyperdrive.\n",
      "YODA: Anoat system. Watch the coords around, you true to save Han...\n",
      "LUKE: Artoo! I've looks for you, I really don't know.\n",
      "CREATURE: (into comlink) Mind b\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "while count < 5:\n",
    "  start_strings = [\"LUKE\",\"BEN\",\"VADER\",\"YODA\"]\n",
    "  start = random.randint(0,len(start_strings)-1)\n",
    "#   all_characters.index(string[c])\n",
    "  #print(evaluate(start_strings[start], 200), '\\n')\n",
    "  a = evaluate(start_strings[start], 200)\n",
    "  if a.find(\"YODA\") != -1 and a.find(\"VADER\") != -1:\n",
    "    print(count + 1)\n",
    "    print(a)\n",
    "    print(\"\\n\\n\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmNrDJ5KufdW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
